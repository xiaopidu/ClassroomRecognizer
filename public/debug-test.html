<!DOCTYPE html>
<html>
<head>
    <title>Debug Face Recognition Test</title>
    <script src="/face-api.js"></script>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 20px;
            background-color: #1e293b;
            color: #f8fafc;
        }
        .container {
            max-width: 800px;
            margin: 0 auto;
        }
        .test-section {
            background-color: #334155;
            padding: 20px;
            margin: 20px 0;
            border-radius: 8px;
        }
        button {
            background-color: #3b82f6;
            color: white;
            border: none;
            padding: 10px 15px;
            border-radius: 4px;
            cursor: pointer;
            margin: 5px;
        }
        button:hover {
            background-color: #2563eb;
        }
        button:disabled {
            background-color: #64748b;
            cursor: not-allowed;
        }
        .result {
            margin-top: 10px;
            padding: 10px;
            border-radius: 4px;
            background-color: #475569;
        }
        .success {
            background-color: #16a34a;
        }
        .error {
            background-color: #dc2626;
        }
        canvas {
            border: 1px solid #64748b;
            margin-top: 10px;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Debug Face Recognition Test</h1>
        
        <div class="test-section">
            <h2>1. Model Loading Test</h2>
            <button id="loadModelBtn">Load Models</button>
            <div id="modelStatus" class="result">Not started</div>
        </div>
        
        <div class="test-section">
            <h2>2. Face Detection Test</h2>
            <p>Upload an image with a face to test detection:</p>
            <input type="file" id="imageUpload" accept="image/*">
            <div id="detectionStatus" class="result">Waiting for image upload</div>
            <canvas id="canvas" width="600" height="400"></canvas>
        </div>
        
        <div class="test-section">
            <h2>3. Recognition Test</h2>
            <p>First register a student, then test recognition:</p>
            <div>
                <input type="text" id="studentName" placeholder="Enter student name">
                <button id="registerBtn" disabled>Register Student</button>
            </div>
            <button id="recognizeBtn" disabled>Recognize Face</button>
            <div id="recognitionStatus" class="result">Waiting for registration</div>
        </div>
    </div>

    <script>
        // Global variables
        let currentImage = null;
        let detection = null;
        let studentDescriptors = [];
        let studentName = '';
        
        // DOM Elements
        const modelStatus = document.getElementById('modelStatus');
        const detectionStatus = document.getElementById('detectionStatus');
        const recognitionStatus = document.getElementById('recognitionStatus');
        const loadModelBtn = document.getElementById('loadModelBtn');
        const imageUpload = document.getElementById('imageUpload');
        const registerBtn = document.getElementById('registerBtn');
        const recognizeBtn = document.getElementById('recognizeBtn');
        const studentNameInput = document.getElementById('studentName');
        const canvas = document.getElementById('canvas');
        const ctx = canvas.getContext('2d');
        
        // Load models
        async function loadModels() {
            try {
                modelStatus.textContent = 'Loading models...';
                modelStatus.className = 'result';
                
                await faceapi.nets.ssdMobilenetv1.loadFromUri('/models');
                await faceapi.nets.faceLandmark68Net.loadFromUri('/models');
                await faceapi.nets.faceRecognitionNet.loadFromUri('/models');
                
                modelStatus.textContent = '✅ Models loaded successfully!';
                modelStatus.className = 'result success';
                loadModelBtn.disabled = true;
            } catch (error) {
                modelStatus.textContent = `❌ Error loading models: ${error.message}`;
                modelStatus.className = 'result error';
                console.error(error);
            }
        }
        
        // Handle image upload
        imageUpload.addEventListener('change', async (e) => {
            if (e.target.files && e.target.files[0]) {
                const file = e.target.files[0];
                const imageUrl = URL.createObjectURL(file);
                
                // Load image
                currentImage = new Image();
                currentImage.onload = async () => {
                    try {
                        detectionStatus.textContent = 'Detecting face...';
                        
                        // Detect face
                        detection = await faceapi.detectSingleFace(currentImage)
                            .withFaceLandmarks()
                            .withFaceDescriptor();
                            
                        if (detection) {
                            detectionStatus.textContent = '✅ Face detected successfully!';
                            detectionStatus.className = 'result success';
                            
                            // Draw on canvas
                            canvas.width = currentImage.width;
                            canvas.height = currentImage.height;
                            ctx.drawImage(currentImage, 0, 0);
                            
                            // Draw bounding box
                            const box = detection.detection.box;
                            ctx.strokeStyle = '#22c55e';
                            ctx.lineWidth = 2;
                            ctx.strokeRect(box.x, box.y, box.width, box.height);
                            
                            // Enable buttons
                            registerBtn.disabled = false;
                            recognizeBtn.disabled = studentDescriptors.length === 0;
                        } else {
                            detectionStatus.textContent = '❌ No face detected in image';
                            detectionStatus.className = 'result error';
                            registerBtn.disabled = true;
                            recognizeBtn.disabled = true;
                        }
                    } catch (error) {
                        detectionStatus.textContent = `❌ Error detecting face: ${error.message}`;
                        detectionStatus.className = 'result error';
                        console.error(error);
                        registerBtn.disabled = true;
                        recognizeBtn.disabled = true;
                    }
                };
                currentImage.src = imageUrl;
            }
        });
        
        // Register student
        registerBtn.addEventListener('click', async () => {
            if (!detection) return;
            
            try {
                studentName = studentNameInput.value.trim();
                if (!studentName) {
                    alert('Please enter a student name');
                    return;
                }
                
                // Store descriptor
                studentDescriptors = [detection.descriptor];
                
                recognitionStatus.textContent = `✅ Student "${studentName}" registered successfully!`;
                recognitionStatus.className = 'result success';
                recognizeBtn.disabled = false;
            } catch (error) {
                recognitionStatus.textContent = `❌ Error registering student: ${error.message}`;
                recognitionStatus.className = 'result error';
                console.error(error);
            }
        });
        
        // Recognize face
        recognizeBtn.addEventListener('click', async () => {
            if (!detection || studentDescriptors.length === 0) return;
            
            try {
                recognitionStatus.textContent = 'Recognizing face...';
                
                // Compute similarity (cosine similarity)
                const queryDescriptor = detection.descriptor;
                const studentDescriptor = studentDescriptors[0];
                
                // Since face-api descriptors are normalized, dot product equals cosine similarity
                let dotProduct = 0;
                for (let i = 0; i < queryDescriptor.length; i++) {
                    dotProduct += queryDescriptor[i] * studentDescriptor[i];
                }
                
                const similarity = dotProduct;
                const percentage = (similarity * 100).toFixed(2);
                
                if (similarity >= 0.92) {
                    recognitionStatus.textContent = `✅ Match found! Student: ${studentName}, Similarity: ${percentage}%`;
                    recognitionStatus.className = 'result success';
                } else if (similarity >= 0.85) {
                    recognitionStatus.textContent = `⚠️ Low confidence match. Student: ${studentName}, Similarity: ${percentage}%`;
                    recognitionStatus.className = 'result';
                } else {
                    recognitionStatus.textContent = `❌ No match found. Similarity: ${percentage}%`;
                    recognitionStatus.className = 'result error';
                }
            } catch (error) {
                recognitionStatus.textContent = `❌ Error recognizing face: ${error.message}`;
                recognitionStatus.className = 'result error';
                console.error(error);
            }
        });
        
        // Initialize
        loadModelBtn.addEventListener('click', loadModels);
    </script>
</body>
</html>